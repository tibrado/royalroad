{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import cross_val_score, train_test_split, RandomizedSearchCV, ShuffleSplit\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.metrics import r2_score\n",
    "from collections import defaultdict\n",
    "\n",
    "# My scripts \n",
    "import nltk_helper as nh\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "plt.style.use('seaborn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data \n",
    "df = pd.read_pickle('../data/data.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_col = ['tags', 'date_last_updated','rating', 'rating_gte_4', 'warning']\n",
    "text_col = ['summary', 'ch1', 'ch2', 'ch3', 'ch4', 'ch5']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get columns \n",
    "X = df.drop(drop_col, axis = 1)\n",
    "y = df[['rating_gte_4', 'rating']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do train test split \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nX_train.drop('title', axis=1, inplace=True)\\nX_test.drop('title', axis=1, inplace=True)\\n\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get titles \n",
    "X_train_titles = X_train.title\n",
    "X_test_titles = X_test.title\n",
    "\n",
    "'''\n",
    "X_train.drop('title', axis=1, inplace=True)\n",
    "X_test.drop('title', axis=1, inplace=True)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Shape: (2053, 95)   Test Shape: (514, 95)\n"
     ]
    }
   ],
   "source": [
    "print(f'Train Shape: {X_train.shape}   Test Shape: {X_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "**Make text columns into NMFs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/noel/anaconda3/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:484: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\"The parameter 'token_pattern' will not be used\"\n"
     ]
    }
   ],
   "source": [
    "# Make text vectors\n",
    "tfid = dict()\n",
    "for col in text_col:\n",
    "    tfid[col] = TfidfVectorizer(tokenizer = nh.prep_text)\n",
    "    \n",
    "    # Fit tfid\n",
    "    tfid[col].fit(X_train[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit NMF \n",
    "def fit_nmf(data, tfid, n = 10, max_i = 500):\n",
    "    # Transform data \n",
    "    X = tfid.transform(data)\n",
    "    \n",
    "    nmf = NMF(n_components = n, max_iter = max_i)\n",
    "    nmf.fit(X)\n",
    "    \n",
    "    W = nmf.transform(X)\n",
    "    H = nmf.components_\n",
    "    \n",
    "    df_H = pd.DataFrame(H, columns = tfid.get_feature_names())\n",
    "    \n",
    "    # Get Topic name \n",
    "    column_names = [f'{data.name}_topic_{i}' for i in range(n)]\n",
    "\n",
    "    df_W = pd.DataFrame(W, index = data.index, columns = column_names)\n",
    "    \n",
    "    # Reset index \n",
    "    df_W\n",
    "    df_H\n",
    "    \n",
    "    return nmf, df_W, df_H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2053, 95)\n",
      "(2053, 10)\n",
      "(2053, 105)\n",
      "(2053, 95)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "_, W, H = fit_nmf(X_train['summary'], tfid['summary'], X_train_titles)\n",
    "# X_train = \n",
    "print(W.shape)\n",
    "print(X_train.merge(W, left_index=True, right_index=True).shape)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([1267,    1,  384, 2220,  453, 1108,  989, 1732,  713, 1129,\n",
      "            ...\n",
      "             705, 2362, 1828, 1778,  277, 1033, 1731,  763,  835, 1653],\n",
      "           dtype='int64', length=2053)\n"
     ]
    }
   ],
   "source": [
    "print(W.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([1267,    1,  384, 2220,  453, 1108,  989, 1732,  713, 1129,\n",
      "            ...\n",
      "             705, 2362, 1828, 1778,  277, 1033, 1731,  763,  835, 1653],\n",
      "           dtype='int64', length=2053)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in text_col:\n",
    "    # NMF or train data \n",
    "    _, W, H = fit_nmf(X_train[col], tfid[col], X_train_titles)\n",
    "    X_train = X_train.merge(W, left_index=True, right_index=True )\n",
    "    \n",
    "    \n",
    "    # NMF or test data \n",
    "    _, W, H = fit_nmf(X_test[col], tfid[col], X_test_titles)\n",
    "    X_test = X_test.merge(W, left_index=True, right_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf_sum, summary_topic, sum_wtopic = fit_nmf(X_train.summary, X_train_titles, 3)\n",
    "nmf_ch1, ch1_ctopic, ch1_wtopic = fit_nmf(X_train.ch1, X_train_titles, 3)\n",
    "nmf_ch2, ch2_ctopic, ch2_wtopic = fit_nmf(X_train.ch2, X_train_titles, 3)\n",
    "nmf_ch3, ch3_ctopic, ch3_wtopic = fit_nmf(X_train.ch3, X_train_titles, 3)\n",
    "nmf_ch4, ch4_ctopic, ch4_wtopic = fit_nmf(X_train.ch4, X_train_titles, 3)\n",
    "nmf_ch5, ch5_ctopic, ch5_wtopic = fit_nmf(X_train.ch5, X_train_titles, 3)\n",
    "# ['summary', 'ch1', 'ch2', 'ch3', 'ch4', 'ch5', 'rating_gte_4', 'warning']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a tifd vector\n",
    "tfid = TfidfVectorizer(tokenizer = nh.prep_text)\n",
    "\n",
    "# Fit summary features \n",
    "tfid.fit(X_train.summary)\n",
    "    \n",
    "# Transform data \n",
    "X = tfid.transform(X_test.summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf_sum.transform(X).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "**Make Random Forest Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 1000, num = 10)]\n",
    "\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 80, num = 11)]\n",
    "max_depth.append(None)\n",
    "\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "print(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "rfr = RandomForestRegressor()\n",
    "\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "rfr_random = RandomizedSearchCV(estimator = rfr, param_distributions = random_grid, \n",
    "                                n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "\n",
    "# Fit the random search model\n",
    "rfr_random.fit(X_train, yreg_train)\n",
    "\n",
    "# Return best param\n",
    "best_params = rfr_random.best_params_\n",
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CV \n",
    "rfr = RandomForestRegressor(random_state=0, **best_params)\n",
    "scores = defaultdict(list)\n",
    "\n",
    "# CV with shuffle splits \n",
    "splitter = ShuffleSplit(100, test_size  = 0.2)\n",
    "names = X.columns\n",
    "\n",
    "# Do some CV \n",
    "for train_index, test_index in splitter.split(X_train, yreg_train):\n",
    "    X_traincv, X_testcv = X_train.values[train_index], X_train.values[test_index]\n",
    "    y_traincv, y_testcv = yreg_train.values[train_index], yreg_train.values[test_index]\n",
    "    \n",
    "    # Fit model \n",
    "    rfr.fit(X_traincv, y_traincv)\n",
    "    \n",
    "    # Make get accuracy \n",
    "    acc = r2_score(y_testcv, rfr.predict(X_testcv))\n",
    "    \n",
    "    # Make some prediction \n",
    "    for i in range(X_train.shape[1]):\n",
    "        X_t = X_testcv.copy()\n",
    "        np.random.shuffle(X_t[:, i])\n",
    "        shuff_acc = r2_score(y_testcv, rfr.predict(X_t))\n",
    "        scores[names[i]].append((acc-shuff_acc)/acc)\n",
    "\n",
    "score_series = pd.DataFrame(scores).mean()\n",
    "scores = pd.DataFrame({'Mean Decrease Accuracy' : score_series})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores.sort_values(by='Mean Decrease Accuracy', ascending = False)[0:10].plot(kind='barh', figsize=(6,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score(yreg_test, rfr.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores.sort_values(by='Mean Decrease Accuracy', ascending = False)[0:10].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfr."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
